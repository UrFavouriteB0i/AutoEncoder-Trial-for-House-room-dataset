{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4328878,"sourceType":"datasetVersion","datasetId":2549275}],"dockerImageVersionId":30804,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Loading up the dataset\n### We'll be using house-room-streets-image-dataset from kaggle for this autoencoder reconstruction trial","metadata":{"_uuid":"09965cc8-6cc0-4d6f-b9ca-0a4c154c30ba","_cell_guid":"fb026eeb-3569-4ed8-b220-e66846e1ddb4","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"import tensorflow as tf","metadata":{"_uuid":"c5f3bb03-9887-4e78-b214-c6676a9d5e62","_cell_guid":"3e397d6d-25bb-44f5-b32c-447ca63df0ab","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-03T08:37:31.768374Z","iopub.execute_input":"2024-12-03T08:37:31.769220Z","iopub.status.idle":"2024-12-03T08:37:46.694729Z","shell.execute_reply.started":"2024-12-03T08:37:31.769145Z","shell.execute_reply":"2024-12-03T08:37:46.693571Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np \nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\nfrom tensorflow import keras\n\nimg_path = \"/kaggle/input/house-rooms-streets-image-dataset/kaggle_room_street_data/house_data\"\nimages = []\n\nfor image in os.listdir(img_path):\n    if image.endswith(\".jpg\"):\n        img = Image.open(os.path.join(img_path, image))  # Resize to (28, 28) if needed\n        img_array = np.array(img)  # Convert image to numpy array (28, 28, 3)\n        \n        # Append to the list\n        images.append(img_array)\n\n# Convert the list of images into a numpy array\n# image_arrays = np.array(images)","metadata":{"_uuid":"f229d136-a140-4269-a212-f08a045fdc74","_cell_guid":"eae91d9d-0665-4c1a-aae7-f84a729ff3f0","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-03T08:38:11.034083Z","iopub.execute_input":"2024-12-03T08:38:11.036128Z","iopub.status.idle":"2024-12-03T08:39:03.155273Z","shell.execute_reply.started":"2024-12-03T08:38:11.036053Z","shell.execute_reply":"2024-12-03T08:39:03.154039Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#we're checking the first image in the dataset\nplt.imshow(image_arrays[0])\nplt.axis(\"off\")\nplt.show()","metadata":{"_uuid":"e887a448-f591-4b7d-86e0-1248b0918663","_cell_guid":"6bcf0338-132d-4b63-9065-21080304723c","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-03T08:39:49.398556Z","iopub.execute_input":"2024-12-03T08:39:49.398979Z","iopub.status.idle":"2024-12-03T08:39:49.624195Z","shell.execute_reply.started":"2024-12-03T08:39:49.398942Z","shell.execute_reply":"2024-12-03T08:39:49.622897Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# typically we need to resized and makes sure the image is uniformly sized by 28 x 28 for autoencoders\nimages_array_resized = np.array([tf.image.resize(img, (32, 32)) for img in image_arrays])","metadata":{"_uuid":"e8785c09-8a6b-40a0-a28f-e76363656e91","_cell_guid":"75b5928c-0f0b-4f31-8b06-379a470f4322","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-03T08:39:59.829813Z","iopub.execute_input":"2024-12-03T08:39:59.830377Z","iopub.status.idle":"2024-12-03T08:40:02.373272Z","shell.execute_reply.started":"2024-12-03T08:39:59.830334Z","shell.execute_reply":"2024-12-03T08:40:02.372010Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## First step to preprocess the image\n### Splitting the dataset into Train and Test Data","metadata":{"_uuid":"7bc7152e-05f1-4c0b-bb4a-1dbdd04fec6a","_cell_guid":"79ef7bd1-0f9b-4a45-be0d-3eeef6707422","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"#before splitting into train and test, we need to normalize within [1 and 0] value\nimages_array_resized = images_array_resized.astype('float32') / 255.","metadata":{"_uuid":"3c4ee398-8c8d-423a-a95c-af8969ddd662","_cell_guid":"534f7ab9-8334-4aef-ab1b-050607b0489b","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-03T08:40:06.827523Z","iopub.execute_input":"2024-12-03T08:40:06.827965Z","iopub.status.idle":"2024-12-03T08:40:06.874184Z","shell.execute_reply.started":"2024-12-03T08:40:06.827927Z","shell.execute_reply":"2024-12-03T08:40:06.872970Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(images_array_resized.shape)","metadata":{"_uuid":"0b0c1937-7dc7-4df8-b323-59657dbfb0e2","_cell_guid":"e428bfc3-ebd0-4f8e-b76a-c00c665b1957","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-03T08:40:09.490027Z","iopub.execute_input":"2024-12-03T08:40:09.490701Z","iopub.status.idle":"2024-12-03T08:40:09.498345Z","shell.execute_reply.started":"2024-12-03T08:40:09.490642Z","shell.execute_reply":"2024-12-03T08:40:09.496790Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n#spltting for 80 : 20 ratio between train and test\nX_train,X_test = train_test_split(images_array_resized, test_size=0.2, random_state=42)","metadata":{"_uuid":"dff85eae-cdbe-40f4-a7e6-edbb7d1e9eb5","_cell_guid":"85579316-7dce-4667-93df-150a6e85e403","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-03T08:40:33.901791Z","iopub.execute_input":"2024-12-03T08:40:33.902295Z","iopub.status.idle":"2024-12-03T08:40:34.465577Z","shell.execute_reply.started":"2024-12-03T08:40:33.902256Z","shell.execute_reply":"2024-12-03T08:40:34.464154Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(X_train.shape)\nprint(X_test.shape)","metadata":{"_uuid":"e4eb8288-4222-4521-bb7d-918ea546e7e4","_cell_guid":"b3ac3a54-16c9-41da-8a56-2c648bfa839e","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-03T08:40:39.549973Z","iopub.execute_input":"2024-12-03T08:40:39.550697Z","iopub.status.idle":"2024-12-03T08:40:39.557458Z","shell.execute_reply.started":"2024-12-03T08:40:39.550656Z","shell.execute_reply":"2024-12-03T08:40:39.556001Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# #Flattening the image\n# X_train = X_train.reshape((len(X_train), np.prod(X_train.shape[1:])))\n# X_test = X_test.reshape((len(X_test), np.prod(X_test.shape[1:])))","metadata":{"_uuid":"6d54f59b-6751-42d5-939b-8adb87232788","_cell_guid":"a0963b00-8f86-4a48-b98c-744adca5a558","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Making the AutoEncoder Model using TensorFlow","metadata":{"_uuid":"d23dd7b0-99c3-4f32-babf-115d87c0112a","_cell_guid":"3699c0a3-3633-4856-8cb4-0ae2b07e0c0e","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"from tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Dense\nfrom keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization, Activation\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.optimizers import Adam\n\ninput_img = Input(shape=(32, 32, 3))\n\n# Encoder \nx = Conv2D(64, (3, 3), padding='same')(input_img)\nx = BatchNormalization()(x)\nx = Activation('relu')(x)\nx = MaxPooling2D((2, 2), padding='same')(x)\nx = Conv2D(32, (3, 3), padding='same')(x)\nx = BatchNormalization()(x)\nx = Activation('relu')(x)\nx = MaxPooling2D((2, 2), padding='same')(x)\nx = Conv2D(16, (3, 3), padding='same')(x)\nx = BatchNormalization()(x)\nx = Activation('relu')(x)\nencoded = MaxPooling2D((2, 2), padding='same')(x)\n\nx = Conv2D(16, (3, 3), padding='same')(encoded)\nx = BatchNormalization()(x)\nx = Activation('relu')(x)\nx = UpSampling2D((2, 2))(x)\nx = Conv2D(32, (3, 3), padding='same')(x)\nx = BatchNormalization()(x)\nx = Activation('relu')(x)\nx = UpSampling2D((2, 2))(x)\nx = Conv2D(64, (3, 3), padding='same')(x)\nx = BatchNormalization()(x)\nx = Activation('relu')(x)\nx = UpSampling2D((2, 2))(x)\nx = Conv2D(3, (3, 3), padding='same')(x)\nx = BatchNormalization()(x)\ndecoded = Activation('sigmoid')(x)\n\n# Autoencoder model \nautoencoder = Model(input_img, decoded) \n\n# Compile the model \nautoencoder.compile(optimizer='adam', loss='binary_crossentropy') \n\n# Summary of the model \nautoencoder.summary()","metadata":{"_uuid":"65d48b66-c212-4fc8-bc9f-df8b4af687cd","_cell_guid":"2f964807-0767-40d0-af3d-cda4fa73b7f6","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-03T08:41:11.618318Z","iopub.execute_input":"2024-12-03T08:41:11.618812Z","iopub.status.idle":"2024-12-03T08:41:11.966963Z","shell.execute_reply.started":"2024-12-03T08:41:11.618769Z","shell.execute_reply":"2024-12-03T08:41:11.965508Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Now you can train the model\nautoencoder.fit(\n    X_train, X_train,  \n    epochs=50,  \n    batch_size=10,  \n    shuffle=True,  \n    validation_data=(X_test, X_test)\n)","metadata":{"_uuid":"fc6c9f11-55e8-49f0-9fd2-a73cd26952c7","_cell_guid":"dc3a586f-f029-4fcc-850b-60b9a567f24f","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-03T08:42:14.751309Z","iopub.execute_input":"2024-12-03T08:42:14.751826Z","iopub.status.idle":"2024-12-03T09:00:14.214304Z","shell.execute_reply.started":"2024-12-03T08:42:14.751787Z","shell.execute_reply":"2024-12-03T09:00:14.212963Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Predict the test data \nreconstructed = autoencoder.predict(X_test) \n\n# Visualize the results \nn = 10  # Number of digits to display \nplt.figure(figsize=(20, 4)) \n\nfor i in range(n): \n    # Display original \n    ax = plt.subplot(2, n, i + 1) \n    plt.imshow(X_test[i].reshape(32, 32, 3)) \n    plt.gray() \n    ax.get_xaxis().set_visible(False) \n    ax.get_yaxis().set_visible(False) \n\n    # Display reconstruction \n    ax = plt.subplot(2, n, i + 1 + n) \n    plt.imshow(reconstructed[i].reshape(32, 32, 3)) \n    plt.gray() \n    ax.get_xaxis().set_visible(False) \n    ax.get_yaxis().set_visible(False) \n\nplt.show()","metadata":{"_uuid":"8461e1c1-61e6-412b-bf6e-69bf63c962c7","_cell_guid":"78a3acc7-4d9d-461e-8a99-47389bfb166d","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-03T09:00:50.659059Z","iopub.execute_input":"2024-12-03T09:00:50.659534Z","iopub.status.idle":"2024-12-03T09:00:52.373981Z","shell.execute_reply.started":"2024-12-03T09:00:50.659496Z","shell.execute_reply":"2024-12-03T09:00:52.372755Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}